{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow and MNIST Multi-Layer Perceptron\n",
    "*** \n",
    "<a href='https://github.com/pick1'> <img src='tensorflow.jpg' /></a>\n",
    "<a href='https://github.com/pick1'> <img src='download.png' /></a>\n",
    "***\n",
    "#### This project used Tensor Flow to analyze the popular [Modified National Institute of Standards and Technology](https://en.wikipedia.org/wiki/MNIST_databaseMNIST) (MNIST) dataset. The dataset contains over 50,000 examples of handwritten numbers. \n",
    "\n",
    "#### Tensor Flow was used to create multi-layer perceptron or 'Deep Learning' network to take, in the pixel information from the MNIST dataset and correctly classify the numbers. This project explored Tensor Flow parameters pertaining to: learning rate; number of training epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Extracting the MNIST dataset from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x71a2272ebeb8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x71a2272fc6a0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x71a2272f81d0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a sample image with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x71a223e4e6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = mnist.train.images[32].reshape(28,28)\n",
    "plt.imshow(sample, cmap = 'Greys');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters:\n",
    "***\n",
    "** Learning Rate: How quickly we adjust the cost function - tradeoffs of large value vs. small value**\n",
    "\n",
    "** Training Epochs: How many training cycles**\n",
    "\n",
    "** Batch size: Batch size of training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Parameters:\n",
    "***\n",
    "**n_classes: Values 0-9 from the MNIST dataset **\n",
    "\n",
    "**n_samples: Number of samples in the dataset**\n",
    "\n",
    "**n_input: Shape of the input array**\n",
    "\n",
    "**n_hidden: The number of hidden layers (2) and number of neurons (256) used. 256 [8-bit color storage](https://en.wikipedia.org/wiki/8-bit_color) used because of way computers store image info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Multi-Layer Perceptron\n",
    "***\n",
    "** Used the [Rectifier Linear Unit (ReLU)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) activation function, simple rectifier function which returns either x or 0, for whichever is greater.**\n",
    "\n",
    "**x: placeholder for data input**\n",
    "\n",
    "**weights: dictionary of weights**\n",
    "\n",
    "**biases: dictionary of bias values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # First hidden layer with ReLU Activation\n",
    "    \n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    # ReLU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last layer (output layer)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Weights and Biases Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "           'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "           'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_6:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_7:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_8:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': <tf.Variable 'Variable_9:0' shape=(256,) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'Variable_10:0' shape=(256,) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases = {'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "           'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "           'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None,n_input])\n",
    "y = tf.placeholder('float', [None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Cost and Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred,labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training the Model with the [.next_batch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)\n",
    "xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0627451 , 0.37647063, 0.18823531,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.2509804 , 0.43921572, 0.62352943, 0.7490196 ,\n",
       "        0.7490196 , 1.        , 0.6862745 , 0.3137255 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37647063,\n",
       "        0.93725497, 0.93725497, 1.        , 0.93725497, 0.56078434,\n",
       "        0.6862745 , 0.7490196 , 0.93725497, 1.        , 0.8745099 ,\n",
       "        0.56078434, 0.3137255 , 0.2509804 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.18823531, 0.8745099 , 0.18823531, 0.18823531,\n",
       "        0.43921572, 0.56078434, 0.5019608 , 0.5019608 , 0.2509804 ,\n",
       "        0.1254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0627451 , 0.8745099 ,\n",
       "        0.1254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.62352943, 0.43921572, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.56078434, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1254902 , 0.62352943, 1.        ,\n",
       "        0.7490196 , 0.3137255 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1254902 , 0.3137255 , 0.62352943,\n",
       "        0.8745099 , 0.37647063, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0627451 , 0.62352943,\n",
       "        0.8117648 , 0.1254902 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2509804 , 0.8745099 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0627451 , 0.8745099 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43921572, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.8117648 ,\n",
       "        0.37647063, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.56078434, 0.5019608 , 0.1254902 , 0.18823531,\n",
       "        0.5019608 , 0.8117648 , 0.2509804 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.56078434, 0.8117648 , 0.7490196 , 0.5019608 , 0.1254902 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x71a216dfb128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xsamp.reshape(28,28), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "**At index there is a 1 in the 5th position which is the correct label/position for the above '5'.**\n",
    "***\n",
    "## Running the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=169.5821\n",
      "Epoch: 2 cost=40.2820\n",
      "Epoch: 3 cost=25.0535\n",
      "Epoch: 4 cost=17.4175\n",
      "Epoch: 5 cost=12.7321\n",
      "Epoch: 6 cost=9.3943\n",
      "Epoch: 7 cost=6.8615\n",
      "Epoch: 8 cost=5.1735\n",
      "Epoch: 9 cost=3.9275\n",
      "Epoch: 10 cost=2.9800\n",
      "Epoch: 11 cost=2.2480\n",
      "Epoch: 12 cost=1.6594\n",
      "Epoch: 13 cost=1.3070\n",
      "Epoch: 14 cost=0.9978\n",
      "Epoch: 15 cost=0.8147\n",
      "Epoch: 16 cost=0.6584\n",
      "Epoch: 17 cost=0.5462\n",
      "Epoch: 18 cost=0.5050\n",
      "Epoch: 19 cost=0.5247\n",
      "Epoch: 20 cost=0.5530\n",
      "Epoch: 21 cost=0.3556\n",
      "Epoch: 22 cost=0.3810\n",
      "Epoch: 23 cost=0.2660\n",
      "Epoch: 24 cost=0.2919\n",
      "Epoch: 25 cost=0.3345\n",
      "Epoch: 26 cost=0.2599\n",
      "Epoch: 27 cost=0.2117\n",
      "Epoch: 28 cost=0.2686\n",
      "Epoch: 29 cost=0.3061\n",
      "Epoch: 30 cost=0.2235\n",
      "Epoch: 31 cost=0.2201\n",
      "Epoch: 32 cost=0.2135\n",
      "Epoch: 33 cost=0.2423\n",
      "Epoch: 34 cost=0.2080\n",
      "Epoch: 35 cost=0.1556\n",
      "Epoch: 36 cost=0.2301\n",
      "Epoch: 37 cost=0.1846\n",
      "Epoch: 38 cost=0.1701\n",
      "Epoch: 39 cost=0.2913\n",
      "Epoch: 40 cost=0.1439\n",
      "Epoch: 41 cost=0.1852\n",
      "Epoch: 42 cost=0.1780\n",
      "Epoch: 43 cost=0.2368\n",
      "Epoch: 44 cost=0.1515\n",
      "Epoch: 45 cost=0.1468\n",
      "Epoch: 46 cost=0.1569\n",
      "Epoch: 47 cost=0.1600\n",
      "Epoch: 48 cost=0.1589\n",
      "Epoch: 49 cost=0.1484\n",
      "Epoch: 50 cost=0.1624\n",
      "Epoch: 51 cost=0.1490\n",
      "Epoch: 52 cost=0.0974\n",
      "Epoch: 53 cost=0.1255\n",
      "Epoch: 54 cost=0.1621\n",
      "Epoch: 55 cost=0.1941\n",
      "Epoch: 56 cost=0.1280\n",
      "Epoch: 57 cost=0.1573\n",
      "Epoch: 58 cost=0.0910\n",
      "Epoch: 59 cost=0.0860\n",
      "Epoch: 60 cost=0.1601\n",
      "Epoch: 61 cost=0.1864\n",
      "Epoch: 62 cost=0.1479\n",
      "Epoch: 63 cost=0.1091\n",
      "Epoch: 64 cost=0.1157\n",
      "Epoch: 65 cost=0.1165\n",
      "Epoch: 66 cost=0.0984\n",
      "Epoch: 67 cost=0.1263\n",
      "Epoch: 68 cost=0.1279\n",
      "Epoch: 69 cost=0.1324\n",
      "Epoch: 70 cost=0.0955\n",
      "Epoch: 71 cost=0.1358\n",
      "Epoch: 72 cost=0.1007\n",
      "Epoch: 73 cost=0.1519\n",
      "Epoch: 74 cost=0.1090\n",
      "Epoch: 75 cost=0.0822\n",
      "Epoch: 76 cost=0.1322\n",
      "Epoch: 77 cost=0.1211\n",
      "Epoch: 78 cost=0.1296\n",
      "Epoch: 79 cost=0.1053\n",
      "Epoch: 80 cost=0.0966\n",
      "Epoch: 81 cost=0.1227\n",
      "Epoch: 82 cost=0.0620\n",
      "Epoch: 83 cost=0.1367\n",
      "Epoch: 84 cost=0.0982\n",
      "Epoch: 85 cost=0.0854\n",
      "Epoch: 86 cost=0.1035\n",
      "Epoch: 87 cost=0.1102\n",
      "Epoch: 88 cost=0.0605\n",
      "Epoch: 89 cost=0.0807\n",
      "Epoch: 90 cost=0.0732\n",
      "Epoch: 91 cost=0.0628\n",
      "Epoch: 92 cost=0.1344\n",
      "Epoch: 93 cost=0.0810\n",
      "Epoch: 94 cost=0.0709\n",
      "Epoch: 95 cost=0.1387\n",
      "Epoch: 96 cost=0.0878\n",
      "Epoch: 97 cost=0.0939\n",
      "Epoch: 98 cost=0.0804\n",
      "Epoch: 99 cost=0.0890\n",
      "Epoch: 100 cost=0.1139\n",
      "Model has completed 100 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Intialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "# Training Epochs\n",
    "# Essentially the max amount of loops possible before we stop\n",
    "# May stop earlier if cost/loss limit was set\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start with cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Convert total number of batches to integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of Training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evalutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_4:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.cast(correct_predictions,'float')\n",
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "***\n",
    "**96% not too bad! But this actually wasn't anywhere near as good as it could be. Running more training epochs with this data (around 20,000) this model could produce accuracy around 99%. This would take a very long time to run!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
